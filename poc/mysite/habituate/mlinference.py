# -*- coding: utf-8 -*-
"""Chatbot  + Image Obj Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QyyKuus4DMmTqGZ1MvwxycBTYC80Uhzd
"""

# pip install gradio
# pip install transformers langchain timm einops

# pip install einops

# from google.colab import drive
# drive.mount('/content/drive')

import os
import torch
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from transformers import (
    DetrImageProcessor,
    DetrForObjectDetection,
    AutoModelForCausalLM,
    AutoTokenizer,
)
import json
from datetime import datetime

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# Function to compute Intersection over Union (IoU) between two bounding boxes
def compute_iou(box1, box2):
    # Calculate intersection coordinates
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])

    # Calculate intersection and union areas
    intersection_area = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)
    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)
    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)
    union_area = float(box1_area + box2_area - intersection_area)

    iou = intersection_area / union_area
    return iou


coco_names = [
    "__background__",
    "person",
    "bicycle",
    "car",
    "motorcycle",
    "airplane",
    "bus",
    "train",
    "truck",
    "boat",
    "traffic light",
    "fire hydrant",
    "N/A",
    "stop sign",
    "parking meter",
    "bench",
    "bird",
    "cat",
    "dog",
    "horse",
    "sheep",
    "cow",
    "elephant",
    "bear",
    "zebra",
    "giraffe",
    "N/A",
    "backpack",
    "umbrella",
    "N/A",
    "N/A",
    "handbag",
    "tie",
    "suitcase",
    "frisbee",
    "skis",
    "snowboard",
    "sports ball",
    "kite",
    "baseball bat",
    "baseball glove",
    "skateboard",
    "surfboard",
    "tennis racket",
    "bottle",
    "N/A",
    "wine glass",
    "cup",
    "fork",
    "knife",
    "spoon",
    "bowl",
    "banana",
    "apple",
    "sandwich",
    "orange",
    "broccoli",
    "carrot",
    "hot dog",
    "pizza",
    "donut",
    "cake",
    "chair",
    "couch",
    "potted plant",
    "bed",
    "N/A",
    "dining table",
    "N/A",
    "N/A",
    "toilet",
    "N/A",
    "tv",
    "laptop",
    "mouse",
    "remote",
    "keyboard",
    "cell phone",
    "microwave",
    "oven",
    "toaster",
    "sink",
    "refrigerator",
    "N/A",
    "book",
    "clock",
    "vase",
    "scissors",
    "teddy bear",
    "hair drier",
    "toothbrush",
]


# Function to extract predictions in a common format
def extract_predictions(model_output, model_name):
    if model_name in ["resnet", "retinanet"]:
        boxes = model_output[0]["boxes"].cpu().detach().numpy()
        scores = model_output[0]["scores"].cpu().detach().numpy()
        labels = model_output[0]["labels"].cpu().detach().numpy()
    elif model_name == "vit":
        # Assuming model_output is the output from the DETR model
        probas = model_output.logits.softmax(-1)[0, :, :-1].cpu().detach().numpy()
        keep = probas.max(-1) > 0.4
        boxes = model_output.pred_boxes[0, keep].cpu().detach().numpy()
        scores = probas[keep].max(-1)
        labels = probas[keep].argmax(-1)
    elif model_name == "yolov8":
        # Assuming results is the output from the YOLOv8 model
        boxes = np.array([box.xyxy[0].tolist() for box in model_output[0].boxes])
        scores = np.array([box.conf[0].item() for box in model_output[0].boxes])
        labels = np.array([int(box.cls[0]) for box in model_output[0].boxes])
    else:
        raise ValueError(f"Unknown model name: {model_name}")

    return [(box, score, label) for box, score, label in zip(boxes, scores, labels)]


# Function to perform object detection using DETR model
def perform_object_detection(image):
    model = (
        DetrImageProcessor.from_pretrained("facebook/detr-resnet-50"),
        DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50").to(device),
    )

    feature_extractor, detector = model
    inputs = feature_extractor(images=image, return_tensors="pt").to(device)
    outputs = detector(**inputs)
    probas = outputs.logits.softmax(-1)[0, :, :-1].cpu().detach().numpy()
    keep = probas.max(-1) > 0.4
    bboxes_scaled = outputs.pred_boxes[0, keep].cpu().detach().numpy()

    predictions = extract_predictions(outputs, "vit")

    # Free up memory by deleting the model and other variables
    del model, feature_extractor, detector, inputs, outputs
    torch.cuda.empty_cache()

    return predictions


# Function to update the JSON file with image data
def update_json_file(image_path, caption, habit, predictions, moondream_outputs):
    json_file = "image_data.json"
    image_name = os.path.basename(image_path)
    image_id = f"{image_name}_{datetime.now().strftime('%Y%m%d%H%M%S')}"

    data = {
        "image_id": image_id,
        "image_path": image_path,
        "caption": caption,
        "habit": habit,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "objects_detected": [
            f"{coco_names[label]} ({score:.2f})" for _, score, label in predictions
        ],
        "color_ambience": moondream_outputs[0],
        "objects_habit": moondream_outputs[1],
        "caption_analysis": moondream_outputs[2],
        "objects_location": moondream_outputs[3],
    }

    if os.path.exists(json_file):
        with open(json_file, "r") as file:
            existing_data = json.load(file)
        existing_data.append(data)
        with open(json_file, "w") as file:
            json.dump(existing_data, file, indent=4)
    else:
        with open(json_file, "w") as file:
            json.dump([data], file, indent=4)


# Function to process the image with Moondream model
def process_with_moondream(image, caption, habit):
    model_id = "vikhyatk/moondream2"
    revision = "2024-03-05"

    model = AutoModelForCausalLM.from_pretrained(
        model_id, trust_remote_code=True, revision=revision
    ).to(device)
    tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)

    enc_image = model.encode_image(image).to(device)
    questions = [
        "Describe the color and ambience of the image.",
        f"What objects in the image are good or bad for the {habit}?",
        f"Based on the {caption}, Please provide suggestions that will help the user in maintaining their {habit}.",
        "Specify as many objects with their relative location that are present in the image.",
        "How would you rate the quality of the image?",
        "Describe the lighting conditions in the image.",
        "What emotion does the image evoke?",
        f"How does the image relate to or impact the {habit}?",
        f"Provide suggestions for improving the {habit} based on the image.",
    ]

    moondream_outputs = []
    for question in questions:
        answer = model.answer_question(enc_image, question, tokenizer)
        if isinstance(answer, torch.Tensor):
            answer = answer.cpu()
        moondream_outputs.append(answer)

    # Free up memory by deleting the model and other variables
    del model, tokenizer, enc_image
    torch.cuda.empty_cache()

    return moondream_outputs


# Function to process the image and update the JSON file
def process_image(image_path, caption, habit):
    image = Image.open(image_path)
    predictions = perform_object_detection(image)
    moondream_outputs = process_with_moondream(image, caption, habit)
    update_json_file(image_path, caption, habit, predictions, moondream_outputs)
    return "Image processed successfully!"


# Example usage
# image_path = "/content/desk.jpg"
caption = "Your image caption : CODING MY MACHINE LEARNING PROJECT"
habit = "Your habit/hobby : maintaing a great clean environment to learn + gaming is my hobby "

# print(process_image(image_path, caption, habit))


def chatbot(image, user_input, history):
    model_id = "vikhyatk/moondream2"
    revision = "2024-03-05"

    model = AutoModelForCausalLM.from_pretrained(
        model_id, trust_remote_code=True, revision=revision
    ).to(device)
    tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)

    enc_image = model.encode_image(image).to(device)

    moondream_answer = model.answer_question(enc_image, user_input, tokenizer)
    if isinstance(moondream_answer, torch.Tensor):
        moondream_answer = moondream_answer.cpu()

    history = history + [[user_input, f"Moondream: {moondream_answer}"]]

    # Free up memory by deleting the model and other variables
    del model, tokenizer, enc_image
    torch.cuda.empty_cache()

    return history, history


history = []
# image_path = "/content/desk2.jpg"
# while True:
#     user_input = input("User: ")
#     history, _ = chatbot(Image.open(image_path), user_input, history)
#     print(history[-1][1])
